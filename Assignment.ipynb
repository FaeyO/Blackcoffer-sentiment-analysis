{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f42793b0-6f41-4323-91a1-c1c4982bd879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: readability in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import needed packages and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "#nltk.download()\n",
    "!pip install readability\n",
    "import textblob            #to import\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pyphen\n",
    "from pyphen import Pyphen\n",
    "import readability\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb911664-1ed2-4e9c-8e08-de27b5e5a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet1']\n"
     ]
    }
   ],
   "source": [
    "#read the input file\n",
    "file = pd.ExcelFile('Input.xlsx')\n",
    "print(file.sheet_names)\n",
    "files = file.parse('Sheet1')\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c76563a0-ee33-465e-87df-e6d5697da998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      https://insights.blackcoffer.com/will-machine-...\n",
       "4      https://insights.blackcoffer.com/will-ai-repla...\n",
       "                             ...                        \n",
       "109    https://insights.blackcoffer.com/blockchain-fo...\n",
       "110    https://insights.blackcoffer.com/the-future-of...\n",
       "111    https://insights.blackcoffer.com/big-data-anal...\n",
       "112    https://insights.blackcoffer.com/business-anal...\n",
       "113    https://insights.blackcoffer.com/challenges-an...\n",
       "Name: URL, Length: 114, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subsetting the url column\n",
    "urls = files.loc[:,'URL']\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b69470-fdbb-4b91-8662-c96fc7d0098e",
   "metadata": {},
   "source": [
    "### DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3cdb63-1a9c-4018-af9b-57b91ecc5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('URL_ID.txt','w',encoding='utf-8') as file:\n",
    "\n",
    "#loop through the url and extract the title and text \n",
    "    for url in urls:\n",
    "        r = requests.get(url)\n",
    "        html_doc = r.text\n",
    "        soup = BeautifulSoup(html_doc)\n",
    "\n",
    "        title = soup.title.string\n",
    "        text = soup.get_text()\n",
    "        \n",
    "        #write the title and text to the file\n",
    "        file.write('Title: ' + title + '\\n')\n",
    "        file.write('Text: ' + text + '\\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa4d00-bbf0-4ed7-9073-7a1dbfbbd90b",
   "metadata": {},
   "source": [
    "### LOADING STOP WORD FILES AND CONVERT TO LIST OF STRINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "571947a3-6ca9-48fb-96e9-7462592c2be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ERNST', 'YOUNG', 'DELOITTE']\n"
     ]
    }
   ],
   "source": [
    "list_word0 = []\n",
    "with open('auditors.txt','r') as file:\n",
    "    for line in file:\n",
    "        str(line)\n",
    "        if line not in list_word0:\n",
    "            list_word0.append(line )\n",
    "        \n",
    "#print(list_word)  \n",
    "my_series0 = pd.Series(list_word0)\n",
    "new_series0 = my_series0.str.strip('\\n')\n",
    "list0 = new_series0.tolist()\n",
    "print(list0[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a2a92-d73f-4e68-9257-c62f640eba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word1 = []\n",
    "with open('currency.txt','r') as file:\n",
    "    for line in file:\n",
    "        str(line)\n",
    "        if line not in list_word0:\n",
    "            list_word1.append(line )\n",
    "        \n",
    "#print(list_word)  \n",
    "my_series1 = pd.Series(list_word1)\n",
    "new_series1 = my_series1.str.strip('\\n')\n",
    "list1 = new_series1.tolist()\n",
    "print(list1[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a376875c-c051-43ff-9504-fb8b60da41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_word = ['ERNST','YOUNG','DELOITTE','TOUCHE','KPMG','PRICEWATERHOUSECOOPERS','PRICEWATERHOUSE','COOPERS','AFGHANI | Afghanistan ','ARIARY | Madagascar ','BAHT | Thailand ','BALBOA | Panama' ,'BIRR | Ethiopia ','BOLIVAR | Venezuela ','BOLIVIANO  | Bolivia ','CEDI | Ghana ','COLON  | Costa Rica' ,'CÓRDOBA  | Nicaragua ','DALASI | Gambia' ,'DENAR | Macedonia (Former Yug. Rep.) ','DINAR | Algeria' ,'DIRHAM  | Morocco ','DOBRA | São Tom and Príncipe ','DONG | Vietnam ','DRAM | Armenia ','ESCUDO  | Cape Verde ','EURO  | Belgium ','FLORIN | Aruba ','FORINT | Hungary ','GOURDE | Haiti ','GUARANI | Paraguay' ,'GULDEN | Netherlands Antilles' ,'HRYVNIA  | Ukraine ','KINA | Papua New Guinea ','KIP | Laos ','KONVERTIBILNA MARKA  | Bosnia-Herzegovina ','KORUNA  | Czech Republic' ,'KRONA | Sweden ','KRONE | Denmark' ,'KROON | Estonia ','KUNA | Croatia' ,'KWACHA | Zambia ','KWANZA | Angola ','KYAT | Myanmar ','LARI | Georgia ','LATS | Latvia ','LEK | Albania ','LEMPIRA | Honduras ','LEONE | Sierra Leone' ,'LEU | Romania' ,'LEV | Bulgaria ','LILANGENI  | Swaziland' ,'LIRA | Lebanon' ,'LITAS | Lithuania ','LOTI | Lesotho ','MANAT | Azerbaijan ','METICAL | Mozambique' ,'NAIRA | Nigeria ','NAKFA | Eritrea ','NEW LIRA | Turkey ','NEW SHEQEL  | Israel ','NGULTRUM  | Bhutan ','NUEVO SOL | Peru ','OUGUIYA  | Mauritania ','PATACA | Macau ','PESO  | Mexico' ,'POUND  | Egypt ','PULA  | Botswana ','QUETZAL | Guatemala ','RAND | South Africa ','REAL  | Brazil ','RENMINBI  | China ','RIAL | Iran' ,'RIEL | Cambodia ','RINGGIT | Malaysia ','RIYAL | Saudi Arabia ','RUBLE | Russia ','RUFIYAA | Maldives ','RUPEE  | India' ,'RUPEE  | Pakistan ','RUPIAH  | Indonesia ','SHILLING  | Uganda ','SOM | Uzbekistan ','SOMONI  | Tajikistan' ,'SPECIAL DRAWING RIGHTS  | International Monetary Fund ','TAKA | Bangladesh ','TALA | Western Samoa ','TENGE | Kazakhstan ','TUGRIK  | Mongolia' ,'VATU | Vanuatu ','WON  | Korea South' ,'YEN | Japan' ,'ZLOTY | Poland']\n",
    "#stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff03f20-9e79-4e2e-bc1d-728032f7181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = ['HUNDRED','THOUSAND','MILLION','BILLION','TRILLION','DATE' ,'ANNUAL','ANNUALLY','ANNUM','YEAR','YEARLY','QUARTER','QUARTERLY','QTR','MONTH','MONTHLY','WEEK','WEEKLY','DAY','DAILY','JANUARY ','FEBRUARY','MARCH','APRIL','MAY','JUNE','JULY','AUGUST','SEPTEMBER','OCTOBER','NOVEMBER','DECEMBER','JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','SEPT','OCT','NOV','DEC','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','SUNDAY','ONE' ,'TWO','THREE','FOUR','FIVE','SIX','SEVEN','EIGHT','NINE','TEN','ELEVEN','TWELVE','THIRTEEN','FOURTEEN','FIFTEEN','SIXTEEN','SEVENTEEN','EIGHTEEN','NINETEEN','TWENTY','THIRTY','FORTY','FIFTY','SIXTY','SEVENTY','EIGHTY','NINETY','FIRST','SECOND','THIRD','FOURTH','FIFTH','SIXTH','SEVENTH','EIGHTH','NINTH','TENTH','I','II','III','IV','V','VI','VII','VIII','IX','X','XI','XII','XIII','XIV','XV','XVI','XVII','XVIII','XIX','XX']\n",
    "#words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e72343-fdcc-41fd-8dd8-e9d49b3a00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2=['ABOUT','ABOVE','AFTER','AGAIN','ALL','AM','AMONG','AN','AND','ANY','ARE','AS','AT','BE','BECAUSE','BEEN','BEFORE','BEING','BELOW','BETWEEN','BOTH','BUT','BY','CAN','DID','DO','DOES','DOING','DOWN','DURING','EACH','FEW','FOR','FROM','FURTHER','HAD','HAS','HAVE','HAVING','HE','HER','HERE','HERS','HERSELF','HIM','HIMSELF','HIS','HOW','IF','IN','INTO','IS','IT','ITS','ITSELF','JUST','ME','MORE','MOST','MY','MYSELF','NO','NOR','NOT','NOW','OF','OFF','ON','ONCE','ONLY','OR','OTHER','OUR','OURS','OURSELVES','OUT','OVER','OWN','SAME','SHE','SHOULD','SO','SOME','SUCH','THAN','THAT','THE','THEIR','THEIRS','THEM','THEMSELVES','THEN','THERE','THESE','THEY','THIS','THOSE','THROUGH','TO','TOO','UNDER','UNTIL','UP','VERY','WAS','WE','WERE','WHAT','WHEN','WHERE','WHICH','WHILE','WHO','WHOM','WHY','WITH','YOU','YOUR','YOURS','YOURSELF','YOURSELVES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c2ca25-f936-4349-9790-37849f2239cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word = []\n",
    "with open('file2.txt','r') as file:\n",
    "    for line in file:\n",
    "        str(line)\n",
    "        if line not in list_word:\n",
    "            list_word.append(line )\n",
    "        \n",
    "#print(list_word)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d7a1fb-ed21-468d-a019-ad24bdea7876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UNITED  ', 'STATE', 'NORTH']\n"
     ]
    }
   ],
   "source": [
    "my_series1 = pd.Series(list_word)\n",
    "new_series1 = my_series1.str.strip('\\n')\n",
    "list4 = new_series1.tolist()\n",
    "print(list4[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367c3ccb-0496-4265-89f6-7d19064ff286",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word2 = []\n",
    "with open('name.txt','r') as file:\n",
    "    for line in file:\n",
    "        str(line)\n",
    "        if line not in list_word2:\n",
    "            list_word2.append(line )\n",
    "        \n",
    "#print(list_word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "763d83be-bf75-4a94-9551-d429c4286a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SMITH  ', 'JOHNSON', 'WILLIAMS', 'JONES', 'BROWN', 'DAVIS', 'MILLER', 'WILSON', 'MOORE', 'TAYLOR']\n"
     ]
    }
   ],
   "source": [
    "my_series2 = pd.Series(list_word2)\n",
    "new_series2 = my_series2.str.strip('\\n')\n",
    "list5 = new_series2.tolist()\n",
    "print(list5[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a22c157-2b55-4482-a8bb-4d4d36f9c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word7 = []\n",
    "with open('name2.txt','r') as file:\n",
    "    for line in file:\n",
    "        str(line)\n",
    "        if line not in list_word7:\n",
    "            list_word7.append(line )\n",
    "        \n",
    "#print(list_word7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47cb1314-7dca-4b60-91e3-a7f66047bd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', \"a's\", 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after']\n"
     ]
    }
   ],
   "source": [
    "my_series7 = pd.Series(list_word7)\n",
    "new_series7 = my_series7.str.strip('\\n')\n",
    "list7 = new_series7.tolist()\n",
    "print(list7[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a204604-9d4a-47ef-aab5-bad9a5dd9acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ERNST', 'YOUNG', 'DELOITTE', 'TOUCHE', 'KPMG']\n"
     ]
    }
   ],
   "source": [
    "stop_word.extend(words2)\n",
    "stop_word.extend(word2)\n",
    "stop_word.extend(list7)\n",
    "stop_word.extend(list4)\n",
    "stop_word.extend(list5)\n",
    "print(stop_word[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f62bb37-08b6-4a8a-90dd-0bb7609a91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_word2 = []\n",
    "with open('neg.txt','r') as file:\n",
    "    for line in file:\n",
    "        str(line)\n",
    "        if line not in neg_word2:\n",
    "            neg_word2.append(line )\n",
    "        \n",
    "#print(neg_word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1477d6c6-ffe1-47b3-a559-a6cc20c13368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    }
   ],
   "source": [
    "my_series8 = pd.Series(neg_word2)\n",
    "new_series8 = my_series8.str.strip('\\n')\n",
    "neg_list = new_series8.tolist()\n",
    "print(neg_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95cc9128-0433-41c8-b65b-8eb845bf3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_word2 = []\n",
    "with open('pos.txt','r') as file:\n",
    "    for line in file:\n",
    "        str(line)\n",
    "        if line not in pos_word2:\n",
    "            pos_word2.append(line )\n",
    "        \n",
    "#print(pos_word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "226789b7-024c-4982-a94c-d29959939e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n"
     ]
    }
   ],
   "source": [
    "my_series9 = pd.Series(pos_word2)\n",
    "new_series9 = my_series9.str.strip('\\n')\n",
    "pos_list = new_series9.tolist()\n",
    "print(pos_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b30bd50b-9148-425a-a0a2-c2b80ac77f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2-faced', '2-faces', 'abnormal']\n"
     ]
    }
   ],
   "source": [
    "neg_word_list = []\n",
    "\n",
    "for name in neg_list:\n",
    "    if name not in stop_word:\n",
    "        neg_word_list.append(name)\n",
    "        \n",
    "print(neg_word_list[:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53fabf03-e743-4435-8006-47e1ee56444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a+', 'abound', 'abounds']\n"
     ]
    }
   ],
   "source": [
    "pos_word_list = []\n",
    "\n",
    "for name in pos_list:\n",
    "    if name not in stop_word:\n",
    "        pos_word_list.append(name)\n",
    "        \n",
    "print(pos_word_list[:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e0babb-e163-48f1-b0df-cd3ff5c98c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7906dc98-061a-430f-8096-e398872bdb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4661824-556f-425b-b576-e4992fe25461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_articles(urls):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def clean_texts(text,stop_words):\n",
    "        #convert text to lowercase\n",
    "        l_text = text.lower()\n",
    "        #remove special characters and punctuation\n",
    "        c_text= re.sub(r'[^\\w\\s]','',l_text)\n",
    "        #remove numbers\n",
    "        n_text = re.sub(r'\\d+','',c_text)\n",
    "        #tokenize the text into words\n",
    "        words = nltk.word_tokenize(n_text)\n",
    "        #remove stop words\n",
    "        stop_words = set(stop_words)\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "        #lemmatize the words\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "        #join the word back into a single string\n",
    "        cleanedtext = ' '.join(words)\n",
    "        \n",
    "        return cleanedtext\n",
    "        \n",
    "    def analyze_text(clean_text):\n",
    "        #tokenize text into words\n",
    "        words = nltk.word_tokenize(clean_text)\n",
    "        #compute the frequency distribution of words\n",
    "        freq_dist = nltk.FreqDist(words)\n",
    "        #positive score\n",
    "        pos_score = 0\n",
    "        for word in words:\n",
    "            if word in pos_word_list:\n",
    "                pos_score +=1\n",
    "        neg_score = 0\n",
    "        for word in words:\n",
    "            if word in neg_word_list:\n",
    "                neg_score += -1\n",
    "        #polarity score\n",
    "        if pos_score + neg_score == 0:\n",
    "            polarity_score = 0.0\n",
    "        else:\n",
    "            polarity_score = ((pos_score - ((neg_score)*(-1)))/ (pos_score + neg_score) + 0.000001)\n",
    "        #subjectivity score\n",
    "        subjectivity_score = (pos_score + neg_score)/(len(words) + 0.000001)\n",
    "        \n",
    "        \n",
    "            \n",
    "        #compute some statistics\n",
    "        word_count = len(words)\n",
    "        avg_word_length = sum(len(word) for word in words) / word_count\n",
    "        sentences = nltk.sent_tokenize(clean_text)\n",
    "        sent_len = len(sentences)\n",
    "        avg_word_per_sent = word_count / sent_len\n",
    "        dic = pyphen.Pyphen(lang='en')\n",
    "        #count complex words\n",
    "        syllable_count = 0\n",
    "        complex_word_count = 0\n",
    "        for word in words:\n",
    "            #Remove the ed suffix fromthe word\n",
    "            if word.endswith('ed'):\n",
    "                word = word[:-2]\n",
    "            #Remove the es suffix from the word\n",
    "            if word.endswith('es'):\n",
    "                word = word[:-2]\n",
    "            #count the number of syllables\n",
    "            syllables = dic.inserted(word).count('-') + 1\n",
    "            syllable_count += syllables\n",
    "            if syllables >= 3:\n",
    "                complex_word_count += 1\n",
    "    \n",
    "        #Define Regular Expression\n",
    "        pattern = r'\\b(I|we|my|ours|us)\\b'\n",
    "        #count he number of personal pronouns\n",
    "        pronoun_count = len(re.findall(pattern,clean_text, flags=re.IGNORECASE))\n",
    "        #gunning fog index\n",
    "        results = readability.getmeasures(clean_text, lang='en')\n",
    "        fog_index = results['readability grades']['GunningFogIndex']\n",
    "    \n",
    "    \n",
    "        return pos_score,((neg_score) * (-1)),polarity_score, subjectivity_score,fog_index,avg_word_per_sent,complex_word_count,word_count,syllable_count,pronoun_count,avg_word_length\n",
    "        \n",
    "    data = []    \n",
    "    for url in urls:\n",
    "        r = requests.get(url)\n",
    "        html_doc = r.text\n",
    "        soup = BeautifulSoup(html_doc)\n",
    "\n",
    "        title = soup.title.string\n",
    "        g_text = soup.get_text()\n",
    "    \n",
    "    \n",
    "        \n",
    "        cleaned_text = clean_texts(g_text,stop_word)\n",
    "        scores = analyze_text(cleaned_text)\n",
    "        \n",
    "        data.append({'url':url, 'title':title, 'scores':scores})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c58dc0c2-1622-4b26-ad19-c601c293958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans  = analyze_articles(urls)\n",
    "#print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2af629cd-85e1-4458-b08d-1e1fda205051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69a641f3-77a9-418d-ba01-235383097785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes |...</td>\n",
       "      <td>(114, 38, 1.000001, 0.04816223064121531, 648.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>(109, 41, 1.000001, 0.05923344942575483, 474.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>(101, 47, 1.000001, 0.03810868028362125, 583.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>(109, 36, 1.000001, 0.05761641668696415, 521.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Will AI Replace Us or Work With Us? | Blackcof...</td>\n",
       "      <td>(102, 32, 1.000001, 0.05131964805621726, 561.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>Blockchain for Payments | Blackcoffer Insights</td>\n",
       "      <td>(55, 32, 1.000001, 0.02295409179345899, 417.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>The future of Investing | Blackcoffer Insights</td>\n",
       "      <td>(72, 18, 1.000001, 0.040540540510104695, 548.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>Big Data Analytics in Healthcare | Blackcoffer...</td>\n",
       "      <td>(75, 54, 1.000001, 0.018356643340597337, 473.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>Business Analytics In The Healthcare Industry ...</td>\n",
       "      <td>(80, 10, 1.000001, 0.07583965322227557, 388.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>(75, 45, 1.000001, 0.028544243550386064, 437.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1    https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2    https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3    https://insights.blackcoffer.com/will-machine-...   \n",
       "4    https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..                                                 ...   \n",
       "109  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110  https://insights.blackcoffer.com/the-future-of...   \n",
       "111  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112  https://insights.blackcoffer.com/business-anal...   \n",
       "113  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "                                                 title  \\\n",
       "0    AI in healthcare to Improve Patient Outcomes |...   \n",
       "1    What if the Creation is Taking Over the Creato...   \n",
       "2    What Jobs Will Robots Take From Humans in The ...   \n",
       "3    Will Machine Replace The Human in the Future o...   \n",
       "4    Will AI Replace Us or Work With Us? | Blackcof...   \n",
       "..                                                 ...   \n",
       "109     Blockchain for Payments | Blackcoffer Insights   \n",
       "110     The future of Investing | Blackcoffer Insights   \n",
       "111  Big Data Analytics in Healthcare | Blackcoffer...   \n",
       "112  Business Analytics In The Healthcare Industry ...   \n",
       "113  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                scores  \n",
       "0    (114, 38, 1.000001, 0.04816223064121531, 648.1...  \n",
       "1    (109, 41, 1.000001, 0.05923344942575483, 474.6...  \n",
       "2    (101, 47, 1.000001, 0.03810868028362125, 583.9...  \n",
       "3    (109, 36, 1.000001, 0.05761641668696415, 521.4...  \n",
       "4    (102, 32, 1.000001, 0.05131964805621726, 561.7...  \n",
       "..                                                 ...  \n",
       "109  (55, 32, 1.000001, 0.02295409179345899, 417.72...  \n",
       "110  (72, 18, 1.000001, 0.040540540510104695, 548.4...  \n",
       "111  (75, 54, 1.000001, 0.018356643340597337, 473.9...  \n",
       "112  (80, 10, 1.000001, 0.07583965322227557, 388.13...  \n",
       "113  (75, 45, 1.000001, 0.028544243550386064, 437.1...  \n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frame = pd.DataFrame(ans)\n",
    "df_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3277848f-3a86-4faa-ba2b-25ca59752354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (114, 38, 1.000001, 0.04816223064121531, 648.1...\n",
       "1      (109, 41, 1.000001, 0.05923344942575483, 474.6...\n",
       "2      (101, 47, 1.000001, 0.03810868028362125, 583.9...\n",
       "3      (109, 36, 1.000001, 0.05761641668696415, 521.4...\n",
       "4      (102, 32, 1.000001, 0.05131964805621726, 561.7...\n",
       "                             ...                        \n",
       "109    (55, 32, 1.000001, 0.02295409179345899, 417.72...\n",
       "110    (72, 18, 1.000001, 0.040540540510104695, 548.4...\n",
       "111    (75, 54, 1.000001, 0.018356643340597337, 473.9...\n",
       "112    (80, 10, 1.000001, 0.07583965322227557, 388.13...\n",
       "113    (75, 45, 1.000001, 0.028544243550386064, 437.1...\n",
       "Name: scores, Length: 114, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frame['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "729ebba4-9dfb-4561-a6e9-f01a8b91d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   url  \\\n",
      "0    https://insights.blackcoffer.com/ai-in-healthc...   \n",
      "1    https://insights.blackcoffer.com/what-if-the-c...   \n",
      "2    https://insights.blackcoffer.com/what-jobs-wil...   \n",
      "3    https://insights.blackcoffer.com/will-machine-...   \n",
      "4    https://insights.blackcoffer.com/will-ai-repla...   \n",
      "..                                                 ...   \n",
      "109  https://insights.blackcoffer.com/blockchain-fo...   \n",
      "110  https://insights.blackcoffer.com/the-future-of...   \n",
      "111  https://insights.blackcoffer.com/big-data-anal...   \n",
      "112  https://insights.blackcoffer.com/business-anal...   \n",
      "113  https://insights.blackcoffer.com/challenges-an...   \n",
      "\n",
      "                                                 title  ps_score  neg_score  \\\n",
      "0    AI in healthcare to Improve Patient Outcomes |...     114.0       38.0   \n",
      "1    What if the Creation is Taking Over the Creato...     109.0       41.0   \n",
      "2    What Jobs Will Robots Take From Humans in The ...     101.0       47.0   \n",
      "3    Will Machine Replace The Human in the Future o...     109.0       36.0   \n",
      "4    Will AI Replace Us or Work With Us? | Blackcof...     102.0       32.0   \n",
      "..                                                 ...       ...        ...   \n",
      "109     Blockchain for Payments | Blackcoffer Insights      55.0       32.0   \n",
      "110     The future of Investing | Blackcoffer Insights      72.0       18.0   \n",
      "111  Big Data Analytics in Healthcare | Blackcoffer...      75.0       54.0   \n",
      "112  Business Analytics In The Healthcare Industry ...      80.0       10.0   \n",
      "113  Challenges and Opportunities of Big Data in He...      75.0       45.0   \n",
      "\n",
      "     pol_score  sub_score         fog  avg_sen  comp_sent  word_count  \\\n",
      "0     1.000001   0.048162  648.158175   1578.0      478.0      1578.0   \n",
      "1     1.000001   0.059233  474.635540   1148.0      323.0      1148.0   \n",
      "2     1.000001   0.038109  583.991249   1417.0      421.0      1417.0   \n",
      "3     1.000001   0.057616  521.448777   1267.0      325.0      1267.0   \n",
      "4     1.000001   0.051320  561.729032   1364.0      383.0      1364.0   \n",
      "..         ...        ...         ...      ...        ...         ...   \n",
      "109   1.000001   0.022954  417.726148   1002.0      276.0      1002.0   \n",
      "110   1.000001   0.040541  548.475676   1332.0      367.0      1332.0   \n",
      "111   1.000001   0.018357  473.928671   1144.0      333.0      1144.0   \n",
      "112   1.000001   0.075840  388.138245    923.0      308.0       923.0   \n",
      "113   1.000001   0.028544  437.107897   1051.0      296.0      1051.0   \n",
      "\n",
      "     syllable  pron  avg_word  \n",
      "0      3480.0   0.0  7.590621  \n",
      "1      2439.0   0.0  7.340592  \n",
      "2      3139.0   0.0  7.593507  \n",
      "3      2658.0   0.0  7.209945  \n",
      "4      2926.0   0.0  7.414956  \n",
      "..        ...   ...       ...  \n",
      "109    2153.0   0.0  7.683633  \n",
      "110    2841.0   0.0  7.387387  \n",
      "111    2442.0   0.0  7.423077  \n",
      "112    2118.0   0.0  7.918743  \n",
      "113    2254.0   0.0  7.525214  \n",
      "\n",
      "[114 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "df_frame[['ps_score','neg_score','pol_score','sub_score','fog','avg_sen','comp_sent','word_count',\n",
    "'syllable','pron','avg_word' ]] = df_frame['scores'].apply(lambda x: pd.Series(x))\n",
    "\n",
    "df_frame = df_frame.drop('scores',axis=1)\n",
    "\n",
    "print(df_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32912248-df39-4d87-9a17-47c809d8c93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>ps_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pol_score</th>\n",
       "      <th>sub_score</th>\n",
       "      <th>fog</th>\n",
       "      <th>avg_sen</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>word_count</th>\n",
       "      <th>syllable</th>\n",
       "      <th>pron</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes |...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.048162</td>\n",
       "      <td>648.158175</td>\n",
       "      <td>1578.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>1578.0</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.590621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.059233</td>\n",
       "      <td>474.635540</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.340592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.038109</td>\n",
       "      <td>583.991249</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.593507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.057616</td>\n",
       "      <td>521.448777</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>2658.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.209945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Will AI Replace Us or Work With Us? | Blackcof...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.051320</td>\n",
       "      <td>561.729032</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.414956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>Blockchain for Payments | Blackcoffer Insights</td>\n",
       "      <td>55.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>417.726148</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>2153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.683633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>The future of Investing | Blackcoffer Insights</td>\n",
       "      <td>72.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>548.475676</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>2841.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.387387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>Big Data Analytics in Healthcare | Blackcoffer...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.018357</td>\n",
       "      <td>473.928671</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>2442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>Business Analytics In The Healthcare Industry ...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.075840</td>\n",
       "      <td>388.138245</td>\n",
       "      <td>923.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.918743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>437.107897</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.525214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1    https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2    https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3    https://insights.blackcoffer.com/will-machine-...   \n",
       "4    https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..                                                 ...   \n",
       "109  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110  https://insights.blackcoffer.com/the-future-of...   \n",
       "111  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112  https://insights.blackcoffer.com/business-anal...   \n",
       "113  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "                                                 title  ps_score  neg_score  \\\n",
       "0    AI in healthcare to Improve Patient Outcomes |...     114.0       38.0   \n",
       "1    What if the Creation is Taking Over the Creato...     109.0       41.0   \n",
       "2    What Jobs Will Robots Take From Humans in The ...     101.0       47.0   \n",
       "3    Will Machine Replace The Human in the Future o...     109.0       36.0   \n",
       "4    Will AI Replace Us or Work With Us? | Blackcof...     102.0       32.0   \n",
       "..                                                 ...       ...        ...   \n",
       "109     Blockchain for Payments | Blackcoffer Insights      55.0       32.0   \n",
       "110     The future of Investing | Blackcoffer Insights      72.0       18.0   \n",
       "111  Big Data Analytics in Healthcare | Blackcoffer...      75.0       54.0   \n",
       "112  Business Analytics In The Healthcare Industry ...      80.0       10.0   \n",
       "113  Challenges and Opportunities of Big Data in He...      75.0       45.0   \n",
       "\n",
       "     pol_score  sub_score         fog  avg_sen  comp_sent  word_count  \\\n",
       "0     1.000001   0.048162  648.158175   1578.0      478.0      1578.0   \n",
       "1     1.000001   0.059233  474.635540   1148.0      323.0      1148.0   \n",
       "2     1.000001   0.038109  583.991249   1417.0      421.0      1417.0   \n",
       "3     1.000001   0.057616  521.448777   1267.0      325.0      1267.0   \n",
       "4     1.000001   0.051320  561.729032   1364.0      383.0      1364.0   \n",
       "..         ...        ...         ...      ...        ...         ...   \n",
       "109   1.000001   0.022954  417.726148   1002.0      276.0      1002.0   \n",
       "110   1.000001   0.040541  548.475676   1332.0      367.0      1332.0   \n",
       "111   1.000001   0.018357  473.928671   1144.0      333.0      1144.0   \n",
       "112   1.000001   0.075840  388.138245    923.0      308.0       923.0   \n",
       "113   1.000001   0.028544  437.107897   1051.0      296.0      1051.0   \n",
       "\n",
       "     syllable  pron  avg_word  \n",
       "0      3480.0   0.0  7.590621  \n",
       "1      2439.0   0.0  7.340592  \n",
       "2      3139.0   0.0  7.593507  \n",
       "3      2658.0   0.0  7.209945  \n",
       "4      2926.0   0.0  7.414956  \n",
       "..        ...   ...       ...  \n",
       "109    2153.0   0.0  7.683633  \n",
       "110    2841.0   0.0  7.387387  \n",
       "111    2442.0   0.0  7.423077  \n",
       "112    2118.0   0.0  7.918743  \n",
       "113    2254.0   0.0  7.525214  \n",
       "\n",
       "[114 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frame"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
